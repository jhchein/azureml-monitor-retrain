$schema: http://azureml/sdk-2-0/SparkComponent.json

name: preprocess_synthetic_data_spark
display_name: Preprocess Synthetic Production Data
is_deterministic: true
type: spark
description: |-
  Preprocess synthetic production data for scoring.
tags:
  production_dataset: synthetic-urifolder-production
inputs:
  input_data:
    type: uri_folder
    optional: False
    description: Production data to preprocess (only file and folder)
    mode: direct
  data_window_end:
    type: string
    optional: False
    description: |
      End of the data window to use for scoring
      Example: 2023-05-01T04:31:57.012Z
  data_window_start:
    type: string
    optional: False
    description: |
      Start of the data window to use for scoring
      Example: 2023-05-01T04:31:57.012Z
outputs:
  preprocessed_input_data:
    type: mltable
    description: Preprocessed production data
    mode: direct

args: --data_window_end ${{inputs.data_window_end}} --data_window_start ${{inputs.data_window_start}} --input_data ${{inputs.input_data}} --preprocessed_input_data ${{outputs.preprocessed_input_data}}

code: .
entry:
  file: run.py
conf:
  spark.synapse.library.python.env: |
    channels:
      - conda-forge
    dependencies:
      - python=3.8
      - pip:
        - scipy~=1.10.0
        - numpy~=1.21.0
        - pandas~=1.4.3
        - azureml-mlflow~=1.49.0
        - mltable~=1.3.0
        - azureml-fsspec
        - fsspec~=2023.4.0
    name: momo-base-spark
  spark.driver.cores: 1
  spark.driver.memory: 2g
  spark.executor.cores: 2
  spark.executor.memory: 2g
  spark.executor.instances: 1
  spark.dynamicAllocation.enabled: true
  spark.dynamicAllocation.minExecutors: 1
  spark.dynamicAllocation.maxExecutors: 4
