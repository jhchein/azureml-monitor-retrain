{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# TODO\n",
        "- [x] Fix MLTable Access\n",
        "- [x] Add today offset to dataset. Split production in half\n",
        "  - [x] We don't need test, rename current to production.\n",
        "  - [x] Which Schedule frequency? -> Weekly?\n",
        "  - [x] Add 7 day offset.\n",
        "- [x] Create Model Outputs (Notebook 01)\n",
        "- [ ] Document Notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Data Set Preparation\n",
        "\n",
        "This notebook will set up the data sets we need for simulating production data and model monitoring, while not using Managed Online Endpoints for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1707995123660
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(\"./data/predictive_maintenance_update.csv\")\n",
        "\n",
        "operators = pd.get_dummies(dataset[\"operator\"])\n",
        "assembly_line_nums = pd.get_dummies(dataset[\"assembly_line_num\"])\n",
        "\n",
        "dataset_dummies = pd.merge(dataset, operators, left_index=True, right_index=True).drop(columns=\"operator\")\n",
        "dataset_dummies = pd.merge(dataset_dummies, assembly_line_nums, left_index=True, right_index=True).drop(columns=\"assembly_line_num\")\n",
        "dataset = dataset_dummies\n",
        "\n",
        "uint8_columns = [\n",
        "    'operator0', 'operator1', 'operator2', 'operator3', 'operator4',\n",
        "    'operator5', 'operator6', 'operator7', 'assembly_0', 'assembly_1',\n",
        "    'assembly_2', 'assembly_3', 'assembly_4', 'assembly_5', 'assembly_6'\n",
        "]\n",
        "\n",
        "# Convert each column in the list to bool\n",
        "for column in uint8_columns:\n",
        "    dataset[column] = dataset[column].astype(bool)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1707995123873
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "dataset[\"timestamp\"] = pd.to_datetime(dataset[\"timestamp\"])\n",
        "\n",
        "# Define timestamps for splitting\n",
        "production_start = pd.to_datetime(\"01/06/2021\")\n",
        "two_weeks_ago = pd.to_datetime(\"today\") - pd.Timedelta(days=14)\n",
        "offset = two_weeks_ago - production_start\n",
        "\n",
        "# Add the offset to all timestamps in the dataset\n",
        "dataset[\"timestamp\"] = dataset[\"timestamp\"] + offset\n",
        "\n",
        "# Update the production_start to today\n",
        "production_start = two_weeks_ago\n",
        "\n",
        "# Split the dataset\n",
        "training = dataset[dataset[\"timestamp\"] <= production_start]\n",
        "production = dataset[dataset[\"timestamp\"] >= production_start]\n",
        "\n",
        "# Sanity checking\n",
        "print(\"reference min: \", training[\"timestamp\"].min(), \" reference max: \", training[\"timestamp\"].max())\n",
        "print(\"production min: \", production[\"timestamp\"].min(), \" production max: \", production[\"timestamp\"].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1707995124341
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "shutil.rmtree(\"data/tmp/\", ignore_errors=True)\n",
        "\n",
        "os.makedirs(\"data/tmp\", exist_ok=False)\n",
        "os.makedirs(\"data/tmp/training\", exist_ok=False)\n",
        "os.makedirs(\"data/tmp/production\", exist_ok=False)\n",
        "os.makedirs(\"data/tmp/dataset\", exist_ok=False)\n",
        "\n",
        "# dataset_dummies.to_parquet(\"data/tmp/dataset/dataset.parquet\", index=False)\n",
        "training.drop(columns=[\"timestamp\"]).to_parquet(\"data/tmp/training/training.parquet\", index=False)\n",
        "production.to_parquet(\"data/tmp/production/production.parquet\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Create AzureML Datasets\n",
        "### Uri_folder Dataset (Training, Production)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.constants import AssetTypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1707995125738
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "\n",
        "VERSION = time.strftime(\"%Y.%m.%d.%H%M%S\", time.gmtime())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1707995129070
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "training_dataset = Data(\n",
        "    path=\"./data/tmp/training/training.parquet\",\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"synthetic Dataset (training) for demonstrating data drift; parquet file\",\n",
        "    name=\"synthetic-urifile-training\",\n",
        "    version=VERSION,\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(training_dataset)\n",
        "\n",
        "production_dataset = Data(\n",
        "    path=\"./data/tmp/production\",\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"synthetic Dataset (production) for demonstrating data drift; parquet file\",\n",
        "    name=\"synthetic-urifolder-production\",\n",
        "    version=VERSION,\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(production_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## MLTable Dataset (Training Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1707995131280
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "data_asset = ml_client.data.get(name=\"synthetic-urifile-training\", version=VERSION)\n",
        "\n",
        "path = {\n",
        "    'file': data_asset.path\n",
        "}\n",
        "\n",
        "tbl = mltable.from_parquet_files(paths=[path])\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1707995132228
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "tbl.save(path=\"data/tmp/mltable-traning\", overwrite=True)\n",
        "\n",
        "dataset = Data(\n",
        "    path=\"data/tmp/mltable-traning\",\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=f\"synthetic Dataset (training, MLTABLE) for demonstrating data drift\",\n",
        "    name=f\"synthetic-mltable-training\",\n",
        "    version=VERSION,\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shutil.rmtree(\"data/tmp/\", ignore_errors=True)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "azureml_py310_sdkv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
